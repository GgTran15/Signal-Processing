---
title: "AMATH 482 Homework 5"
author: "Gg Tran"
date: "March 14th, 2019"
output: pdf_document
---

#Abstract



#I. Introduction and Overview

Dynamical Mode Decomposition (DMD) is a data-driven method to model complex, nonlinear system whose underlying equations are unknown. Using data snapshots in time of the system, the DMD can build the low-dimensional model of the system and make short-timed prediction. The DMD assumes that each data snapshot is collected over regularly spaced interval of time $\Delta t$.$^2$ The DMD incorporates principle component analysis and Fourier analysis **[..]** The advantage of DMD is that it requires no assumptions about the system. 

#### Koopman Operator
**[...............]**

#II. Theoretical Background
Given a nonlinear system that is evolving continuously in time, the DMD approximates such system using a continuous linear system

\setlength{\leftskip}{4cm}

$\frac{d\mathbf{x}}{dt}=$$\mathbf{Ax}$, with $\mathbf{x}(t)$ denoting the state of the system at time $t$.

\setlength{\leftskip}{0pt}

The solutions to the system in continuous time can be represented with 

\setlength{\leftskip}{4cm}

$\mathbf{x}(t)=\sum_{k=1}^{n} \boldsymbol{\phi}_{k} \exp \left(\omega_{k} t\right) b_{k}=\boldsymbol{\Phi} \exp (\Omega t) \mathbf{b}$

\setlength{\leftskip}{0pt}

whereas the solutions at each discretized time can be computed with

\setlength{\leftskip}{4cm}

$\mathbf{x}_{k}=\sum_{j=1}^r \boldsymbol{\phi}_j \lambda_j^k b_j=\boldsymbol{\Phi} \Lambda^k \mathbf{b}$

\setlength{\leftskip}{0pt}

with $r << n$, $\boldsymbol{\Phi}$ are the eigenvectors, $\Lambda^k$ **[....]**

#### Koopman operator
Since the DMD seeks to build a linear model that best approximates a nonlinear system, the goal is to find the optimal Koopman operator $\mathbf{A}$ that maps one data snapshot to another. All *m* data snapshots in time are arranged into matrix **X**. To reduce approximation error, data matrix **X** is split into two matrices with column vectors: 

\setlength{\leftskip}{4cm}

$\mathbf{X} = [\mathbf{x}_{1} \quad \mathbf{x}_{2} \quad...\quad \mathbf{x_{m-1}}]$ and $\mathbf{X^{\prime}} = [\mathbf{x}_{2} \quad \mathbf{x}_{3} \quad...\quad \mathbf{x_m}]$

\setlength{\leftskip}{0pt}

From here, **A** can be computed by: $\mathbf{A}=\mathbf{X}^{\prime}\mathbf{X}^{\dagger}$, with $\mathbf{X}^{\dagger}$: Moore-Penrose pseudo-inverse.

Koopman operator $\mathbf{A}$ is also used to make prediction so that $\mathbf{x}_{k+1}=\mathbf{A x}_k$

#### Steps in building the Dynamic Mode Decomposition algorithm
 Do SVD on **X1** to get **U**, **S**, **V** $\rightarrow$ Pick the number of rank base on the number of dominant modes.  $\rightarrow$ Build **A** using **X2** and the rank-truncated **U**, **S**, **V** $\rightarrow$ Do eigendecomposition on **A** **BLABLABLABLABLA[......................................]**


#III. Algorithm Implementation and Development

- Building the data matrix X**: represent the video as a sequence of picture frames$\rightarrow$Reshape each frame as a column vector$\rightarrow$Split the data **X** into **X1** and **X2** (shifted data).

- Apply DMD algorithm to reconstruct data using DMD modes. We use the **Dmd.m** function (see Appendix B) from Kutz's textbook to reconstruct **x** into **Xdmd**. We find 2 singular values that are the dominant modes, but we set rank **r = 10** as this yield better video reconstruction.

- **Split the Xdmd into background matrix and foreground matrix**. **XSparseDmd** represents the foreground. **XdmdLowRank** represents the background. We construct **XdmdLowRank** using **abs(omega) < 0.5**. This cutoff is chosen based on manually looking at all the **omega** values and deciding which cutoff range is closest to 0 while still captures all the background.

- Get the real value of **XsparseDmd** $\rightarrow$Put all residual negative values in **XsparseDmd** into **R** $\rightarrow$ Subtract **R** from **XsparseDmd**.

- Reconstruct the background and foreground frames.

#IV. Computational Results
Overall, with **rank = 10**, across all 3 videos, we are able to separate the foreground (right) from the background (left). There are still some contours of the foreground residing in the extracted background, but those contours are completely unmoving.

In the corgi surveillance video **FIGURE**, we can easily separate out the foreground (the moving corgi) and the background (the kitchen). In the video, the only thing moving is the corgi, while the surrounding background (the kitchen) is completely still. However, while we can extract all the corgi's movement into a separate foreground, we are unable to extract a clearer shape of the moving corgi. We surmise that this might due to the poor quality of the surveillance camera: The video is very blurry, showing poor sharpness and contrast between objects.

In the boxing surveillance video **FIGURE**, the foreground is the two moving boxers, and the background is the audience. There are some slight movements in the background (e.g the referee walking back and forth). However the algorithm extracts  out a very clear representation and movement of the two fighters. 

In the corgi twerking video, the camera is moving so both the background and the foreground are moving. However the video quality is great, with clear sharpness and contrast between objects. The algorithm does a pretty good job separating out the main background, while still captures the shaking movement of the corgi.

```{r, echo = FALSE}
library(knitr)
```

```{r, echo = FALSE, fig.align="center"}
```
Figure 1: 

```{r, echo = FALSE, fig.align="center"}
```
Figure 2: Spectrograms of the music when undersampling (very large window translation) versus when oversampling (very small window translation)

```{r, echo = FALSE, fig.align="center"}
```
Figure 3:



#V. Summary and Conclusions

> The effectiveness of the algorithm is affected by 

> the quality of the movie clip: The boxing video has better quality e.g better light contrast. Whereas the corgi video has poorer quality where objects edges and contrasts are blurrier - the foreground seems "blend in" with the background, thus making it harder to extract a clear foreground. In the better video, the algorithm better separates the background and the foreground. The foreground is clearer. 

> Adding in the residuals into the X dmd low rank (the foreground) produces worse results.


#Appendix A: MATLAB functions 
#Appendix B: MATLAB codes